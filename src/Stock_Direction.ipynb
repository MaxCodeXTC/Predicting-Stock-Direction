{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stock-Direction.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranjalchaubey/Predicting-Stock-Direction/blob/master/src/Stock_Direction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrA9m16Wv5Hq",
        "colab_type": "text"
      },
      "source": [
        "# Stock Direction\n",
        "In this notebook we are going to use Random Forests to predict the direction  \n",
        "of stocks for the next trading day.  \n",
        "In more technical terms, we are going to try and predict the _**Momentum**_  \n",
        "of the stocks.  \n",
        "Based on the momentum, we are going to give the following signals to the user  \n",
        "1. Buy (_+ve momentum_)\n",
        "2. Sell (_-ve momentum_)\n",
        "3. Hold (_neutral_)  \n",
        "\n",
        "This system will work on the daily closing prices and will generate the signals by predicting the momentum for the next trading day. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rm2r2nZLyPpP",
        "colab_type": "text"
      },
      "source": [
        "##Setup The Colab Environment \n",
        "Install and Import the required libraries.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHPgN_JWRont",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Debug Flag\n",
        "_GLOBAL_DEBUG_ = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPIEFSuJz3_Z",
        "colab_type": "code",
        "outputId": "aea029cb-34c7-4651-c6bf-970a5781dfba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Install the yFinance library \n",
        "!pip install -q yfinance "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for yfinance (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHORMgl6zxqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# yFinance will help us fetch the data for our dataset\n",
        "import yfinance as yf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALAkdXJVv0IL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Mining and plotting \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70KcLBXhy08M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Classifier \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujJcQHQTzV2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Other Libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tqdm import tqdm\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "# if in Google Colaboratory\n",
        "try:\n",
        "    from google.colab import drive\n",
        "except:\n",
        "    pass\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eXZSuMUzZ6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Configure Pandas Display Options\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMqMKQ6pzc8o",
        "colab_type": "code",
        "outputId": "d524036b-963a-48f6-ef5a-b3a7b1e287d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "# Since I am running this notebook on Colab, \n",
        "# Let's try and get some system information \n",
        "import platform\n",
        "print('System Processor: ', platform.processor(), '\\n')\n",
        "!nvidia-smi"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "System Processor:  x86_64 \n",
            "\n",
            "Tue Oct  1 19:49:37 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 430.40       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDkAce5w_LT4",
        "colab_type": "text"
      },
      "source": [
        "## Load the Data\n",
        "We will extract the 5 year history of 10 stocks chosen by the user. \n",
        "\n",
        "<br/>Here, we will take the following stocks as an example\n",
        "1. Facebook FB\n",
        "2. Apple AAPL\n",
        "3. Amazon AMZN\n",
        "4. Netflix NFLX\n",
        "5. Google GOOGL\n",
        "6. Starbucks SBUX\n",
        "7. Exxon Mobil XOM\n",
        "8. Johnson & Johnson JNJ\n",
        "9. Bank of America BAC\n",
        "10. General Motors GM\n",
        "\n",
        "<br/>In the actual application, stock selection will be done by the user. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO3eCg6TzeeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# List of stock tickers \n",
        "# this info will come from the user, perhaps in the form of a pickle file \n",
        "ticker_list = ['FB', 'AAPL', 'AMZN', 'NFLX', 'GOOGL', 'SBUX', 'XOM', 'JNJ',\\\n",
        "               'BAC', 'GM']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nk95CIFIW9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fetch_ticker_data(tickers): \n",
        "    \"\"\"\n",
        "    Fetch 5 years of historical data for the 'tickers', from Yahoo Finance.    \n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    tickers : List   \n",
        "        List of stocks chosen by the user.   \n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    data : Dataframe \n",
        "        Pandas df with historical stock data time series. \n",
        "    \"\"\"\n",
        "    # Debug \n",
        "    _LOCAL_DEBUG_ = False\n",
        "\n",
        "    # Get the Data from Yahoo! Finance\n",
        "    data = yf.download(tickers, start=\"2009-01-01\", end=\"2019-09-07\")\n",
        "    if _GLOBAL_DEBUG_ and _LOCAL_DEBUG_:\n",
        "        display(data.head(20))\n",
        "\n",
        "    # Data is multi-indexed on the columns \n",
        "    # Make it multi-index on the rows, to make it \n",
        "    # fit for consumption by the RandomForestClassiffier\n",
        "    data = data.stack(1) \n",
        "    if _GLOBAL_DEBUG_ and _LOCAL_DEBUG_:\n",
        "        display(data.head(20))\n",
        "\n",
        "    # Drop all the columns except for Adj Close & Volume\n",
        "    data = data[['Adj Close', 'Volume']]\n",
        "    # Rename the column names \n",
        "    data.columns = ['close', 'volume']  \n",
        "    if _GLOBAL_DEBUG_ and _LOCAL_DEBUG_:\n",
        "        display(data.head(20))\n",
        "\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPtLBV75SD08",
        "colab_type": "code",
        "outputId": "44662d5e-9ed5-4eb9-8bd4-94fed6e3d04c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Go fetch! \n",
        "dataset = fetch_ticker_data(tickers=ticker_list)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  10 of 10 downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lwSmUWMplIb",
        "colab_type": "text"
      },
      "source": [
        "## Data Preprocessing\n",
        "Now that we have the data downloaded and neatly organized in a dataframe,  \n",
        "time to do some necessary preprocessing.  \n",
        "In particular, we are going to use the _log returns_ of the stocks to create a  \n",
        "target column, called `target`.  \n",
        "The target variable will be created using the following criteria  \n",
        "```\n",
        "  -1 = Sell = ret < -0.0015\n",
        "   0 = Hold = -0.0015 < ret < 0.0015 \n",
        "   1 = Buy  = ret > .0015\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4H28uqBYSjT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classify_return(ret):\n",
        "    \"\"\"\n",
        "    Classify the returns as -1, 0 or 1.\n",
        "    -1 = Sell = ret < -0.0015\n",
        "    0 = Hold = -0.0015 < ret < 0.0015 \n",
        "    1 = Buy  = ret > .0015\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    ret : Float   \n",
        "        Stock return for the current day, d. \n",
        "        retd = log(retd) - log(ret(d-1))\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    ret_category : Integer\n",
        "        Category of return, ret. \n",
        "        -1, 0 or 1. \n",
        "    \"\"\"\n",
        "    ret_category = 0\n",
        "    \n",
        "    if ret < -0.0015: \n",
        "        ret_category = -1\n",
        "    elif -0.0015 < ret and ret < 0.0015:\n",
        "        ret_category = 0\n",
        "    elif ret > 0.0015:\n",
        "        ret_category = 1\n",
        "\n",
        "    return ret_category"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofeAWTqHr1tv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_preprocess(dataset):\n",
        "    \"\"\"\n",
        "    Calculates log returns and creates the 'target' column.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataset : Pandas Dataframe\n",
        "    Dataframe containing price, volume and other \n",
        "    information of the chosen stocks. \n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Processed dataframe with two additional columns,\n",
        "    'returns' and 'target'. \n",
        "    returns = log returns of prices \n",
        "    target = target column for the classifier to predict\n",
        "    \"\"\"\n",
        "    # Debug Flag\n",
        "    _LOCAL_DEBUG_ = False \n",
        "\n",
        "    # Advance the prices by 1 day to calculate the log returns \n",
        "    dataset['shift'] = dataset.groupby(level=1)['close'].shift(1)\n",
        "    if _GLOBAL_DEBUG_ and _LOCAL_DEBUG_:\n",
        "        dataset.head(30)\n",
        "\n",
        "    # Create the 'returns' column\n",
        "    dataset['returns'] = np.log(dataset['close']) - np.log(dataset['shift'])\n",
        "    if _GLOBAL_DEBUG_ and _LOCAL_DEBUG_:\n",
        "        dataset.head(30)   \n",
        "\n",
        "    # Drop the first row as it contains NANs in the returns column\n",
        "    dataset.drop(index = dataset.index.levels[0].values[0], level=0,\\\n",
        "                 inplace=True)\n",
        "    if _GLOBAL_DEBUG_ and _LOCAL_DEBUG_:\n",
        "        dataset.head(30)\n",
        "\n",
        "    # Create the 'target' column for the classifier \n",
        "    # Shift the 'target' into the future by 1 day as well by 'shift(-1)'\n",
        "    # We do this since we are predicting returns of the 'next day close'\n",
        "    dataset['target'] = dataset['returns'].apply(lambda x: classify_return(x))\n",
        "    dataset['target'] = dataset.groupby(level=1)['target'].shift(-1)\n",
        "    if _GLOBAL_DEBUG_ and _LOCAL_DEBUG_:\n",
        "        dataset.head(30)\n",
        "\n",
        "    # Drop the 'shift' column as it was only temporary to calculate 'returns'\n",
        "    dataset.drop(['shift'], axis=1, inplace=True)\n",
        "    if _GLOBAL_DEBUG_ and _LOCAL_DEBUG_:\n",
        "        dataset.head(30)\n",
        "\n",
        "    # Handle NANs\n",
        "    # We keep it simple at the moment and simply drop off rows with NANs \n",
        "    if _GLOBAL_DEBUG_ and _LOCAL_DEBUG_:\n",
        "        print(dataset.shape)\n",
        "        print(dataset.isna().sum())\n",
        "    dataset.dropna(how='any', inplace=True)\n",
        "    if _GLOBAL_DEBUG_ and _LOCAL_DEBUG_:\n",
        "        print(dataset.shape)\n",
        "        print(dataset.isna().sum())\n",
        "\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zi4Q9kt2zh7a",
        "colab_type": "text"
      },
      "source": [
        "Pre-process the downloaded dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVvKp_pvzBxz",
        "colab_type": "code",
        "outputId": "034bf836-5f19-4eaa-8d23-75a06f40817e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "display(dataset.head(20))\n",
        "dataset = data_preprocess(dataset)\n",
        "display(dataset.head(20))\n",
        "display(dataset.tail())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"8\" valign=\"top\">2009-01-02</th>\n",
              "      <th>AAPL</th>\n",
              "      <td>11.31</td>\n",
              "      <td>186503800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AMZN</th>\n",
              "      <td>54.36</td>\n",
              "      <td>7296400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BAC</th>\n",
              "      <td>12.89</td>\n",
              "      <td>86580700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GOOGL</th>\n",
              "      <td>160.82</td>\n",
              "      <td>7213700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>JNJ</th>\n",
              "      <td>43.72</td>\n",
              "      <td>11638900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NFLX</th>\n",
              "      <td>4.27</td>\n",
              "      <td>6605200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SBUX</th>\n",
              "      <td>4.22</td>\n",
              "      <td>14885400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XOM</th>\n",
              "      <td>58.45</td>\n",
              "      <td>35803700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"8\" valign=\"top\">2009-01-05</th>\n",
              "      <th>AAPL</th>\n",
              "      <td>11.79</td>\n",
              "      <td>295402100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AMZN</th>\n",
              "      <td>54.06</td>\n",
              "      <td>9509800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BAC</th>\n",
              "      <td>12.57</td>\n",
              "      <td>93640500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GOOGL</th>\n",
              "      <td>164.19</td>\n",
              "      <td>9768200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>JNJ</th>\n",
              "      <td>43.28</td>\n",
              "      <td>15540000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NFLX</th>\n",
              "      <td>4.56</td>\n",
              "      <td>13044500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SBUX</th>\n",
              "      <td>4.25</td>\n",
              "      <td>16070600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XOM</th>\n",
              "      <td>58.44</td>\n",
              "      <td>43340100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">2009-01-06</th>\n",
              "      <th>AAPL</th>\n",
              "      <td>11.60</td>\n",
              "      <td>322327600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AMZN</th>\n",
              "      <td>57.36</td>\n",
              "      <td>11080100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BAC</th>\n",
              "      <td>12.84</td>\n",
              "      <td>111015400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GOOGL</th>\n",
              "      <td>167.20</td>\n",
              "      <td>12837500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   close       volume\n",
              "Date                                 \n",
              "2009-01-02 AAPL    11.31  186503800.0\n",
              "           AMZN    54.36    7296400.0\n",
              "           BAC     12.89   86580700.0\n",
              "           GOOGL  160.82    7213700.0\n",
              "           JNJ     43.72   11638900.0\n",
              "           NFLX     4.27    6605200.0\n",
              "           SBUX     4.22   14885400.0\n",
              "           XOM     58.45   35803700.0\n",
              "2009-01-05 AAPL    11.79  295402100.0\n",
              "           AMZN    54.06    9509800.0\n",
              "           BAC     12.57   93640500.0\n",
              "           GOOGL  164.19    9768200.0\n",
              "           JNJ     43.28   15540000.0\n",
              "           NFLX     4.56   13044500.0\n",
              "           SBUX     4.25   16070600.0\n",
              "           XOM     58.44   43340100.0\n",
              "2009-01-06 AAPL    11.60  322327600.0\n",
              "           AMZN    57.36   11080100.0\n",
              "           BAC     12.84  111015400.0\n",
              "           GOOGL  167.20   12837500.0"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>returns</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"8\" valign=\"top\">2009-01-05</th>\n",
              "      <th>AAPL</th>\n",
              "      <td>11.79</td>\n",
              "      <td>295402100.0</td>\n",
              "      <td>0.041564</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AMZN</th>\n",
              "      <td>54.06</td>\n",
              "      <td>9509800.0</td>\n",
              "      <td>-0.005534</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BAC</th>\n",
              "      <td>12.57</td>\n",
              "      <td>93640500.0</td>\n",
              "      <td>-0.025139</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GOOGL</th>\n",
              "      <td>164.19</td>\n",
              "      <td>9768200.0</td>\n",
              "      <td>0.020739</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>JNJ</th>\n",
              "      <td>43.28</td>\n",
              "      <td>15540000.0</td>\n",
              "      <td>-0.010115</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NFLX</th>\n",
              "      <td>4.56</td>\n",
              "      <td>13044500.0</td>\n",
              "      <td>0.065709</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SBUX</th>\n",
              "      <td>4.25</td>\n",
              "      <td>16070600.0</td>\n",
              "      <td>0.007084</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XOM</th>\n",
              "      <td>58.44</td>\n",
              "      <td>43340100.0</td>\n",
              "      <td>-0.000171</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"8\" valign=\"top\">2009-01-06</th>\n",
              "      <th>AAPL</th>\n",
              "      <td>11.60</td>\n",
              "      <td>322327600.0</td>\n",
              "      <td>-0.016247</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AMZN</th>\n",
              "      <td>57.36</td>\n",
              "      <td>11080100.0</td>\n",
              "      <td>0.059253</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BAC</th>\n",
              "      <td>12.84</td>\n",
              "      <td>111015400.0</td>\n",
              "      <td>0.021252</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GOOGL</th>\n",
              "      <td>167.20</td>\n",
              "      <td>12837500.0</td>\n",
              "      <td>0.018166</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>JNJ</th>\n",
              "      <td>43.02</td>\n",
              "      <td>22097600.0</td>\n",
              "      <td>-0.006026</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NFLX</th>\n",
              "      <td>4.71</td>\n",
              "      <td>12065900.0</td>\n",
              "      <td>0.032365</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SBUX</th>\n",
              "      <td>4.38</td>\n",
              "      <td>17609800.0</td>\n",
              "      <td>0.030130</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XOM</th>\n",
              "      <td>57.49</td>\n",
              "      <td>41906100.0</td>\n",
              "      <td>-0.016390</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">2009-01-07</th>\n",
              "      <th>AAPL</th>\n",
              "      <td>11.35</td>\n",
              "      <td>188262200.0</td>\n",
              "      <td>-0.021787</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AMZN</th>\n",
              "      <td>56.20</td>\n",
              "      <td>7942700.0</td>\n",
              "      <td>-0.020430</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BAC</th>\n",
              "      <td>12.33</td>\n",
              "      <td>112810000.0</td>\n",
              "      <td>-0.040530</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GOOGL</th>\n",
              "      <td>161.17</td>\n",
              "      <td>8980000.0</td>\n",
              "      <td>-0.036731</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   close       volume   returns  target\n",
              "Date                                                   \n",
              "2009-01-05 AAPL    11.79  295402100.0  0.041564    -1.0\n",
              "           AMZN    54.06    9509800.0 -0.005534     1.0\n",
              "           BAC     12.57   93640500.0 -0.025139     1.0\n",
              "           GOOGL  164.19    9768200.0  0.020739     1.0\n",
              "           JNJ     43.28   15540000.0 -0.010115    -1.0\n",
              "           NFLX     4.56   13044500.0  0.065709     1.0\n",
              "           SBUX     4.25   16070600.0  0.007084     1.0\n",
              "           XOM     58.44   43340100.0 -0.000171    -1.0\n",
              "2009-01-06 AAPL    11.60  322327600.0 -0.016247    -1.0\n",
              "           AMZN    57.36   11080100.0  0.059253    -1.0\n",
              "           BAC     12.84  111015400.0  0.021252    -1.0\n",
              "           GOOGL  167.20   12837500.0  0.018166    -1.0\n",
              "           JNJ     43.02   22097600.0 -0.006026    -1.0\n",
              "           NFLX     4.71   12065900.0  0.032365    -1.0\n",
              "           SBUX     4.38   17609800.0  0.030130    -1.0\n",
              "           XOM     57.49   41906100.0 -0.016390    -1.0\n",
              "2009-01-07 AAPL    11.35  188262200.0 -0.021787     1.0\n",
              "           AMZN    56.20    7942700.0 -0.020430     1.0\n",
              "           BAC     12.33  112810000.0 -0.040530    -1.0\n",
              "           GOOGL  161.17    8980000.0 -0.036731     1.0"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>returns</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">2019-09-05</th>\n",
              "      <th>GOOGL</th>\n",
              "      <td>1212.19</td>\n",
              "      <td>1319700.0</td>\n",
              "      <td>0.024992</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>JNJ</th>\n",
              "      <td>128.58</td>\n",
              "      <td>4754100.0</td>\n",
              "      <td>-0.002175</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NFLX</th>\n",
              "      <td>293.25</td>\n",
              "      <td>8966800.0</td>\n",
              "      <td>0.005917</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SBUX</th>\n",
              "      <td>95.56</td>\n",
              "      <td>5514400.0</td>\n",
              "      <td>-0.005739</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XOM</th>\n",
              "      <td>70.27</td>\n",
              "      <td>9901500.0</td>\n",
              "      <td>0.014044</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    close     volume   returns  target\n",
              "Date                                                  \n",
              "2019-09-05 GOOGL  1212.19  1319700.0  0.024992    -1.0\n",
              "           JNJ     128.58  4754100.0 -0.002175    -1.0\n",
              "           NFLX    293.25  8966800.0  0.005917    -1.0\n",
              "           SBUX     95.56  5514400.0 -0.005739     1.0\n",
              "           XOM      70.27  9901500.0  0.014044     1.0"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fADHPJVg4XpP",
        "colab_type": "text"
      },
      "source": [
        "## Feature Engineering \n",
        "Leaving this section blank at the moment. Will come back at a later time. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha8WSnPOzzuu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cET3Gtd47bcf",
        "colab_type": "text"
      },
      "source": [
        "## Train Test Split \n",
        "Split the data into testing and training sets.  \n",
        "In production, there's going to be only re-training of the model that we have  \n",
        "chosen with the specified hyper-parameters. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0eNFIrW-Uao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_test_split(dataset, features, target, train_size, test_size):\n",
        "    \"\"\"\n",
        "    Generate the train and test dataset.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataset : DataFrame\n",
        "        All the samples including target\n",
        "    features : List\n",
        "        List of the names of columns that are features\n",
        "    target : String\n",
        "        Name of column that is the target (in our case, 'target')\n",
        "    train_size : float\n",
        "        The proportion of the data used for the training dataset\n",
        "    test_size : float\n",
        "        The proportion of the data used for the test dataset\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    x_train : DataFrame\n",
        "        The train input samples\n",
        "    x_test : DataFrame\n",
        "        The test input samples\n",
        "    y_train : Pandas Series\n",
        "        The train target values\n",
        "    y_test : Pandas Series\n",
        "        The test target values\n",
        "    \"\"\"\n",
        "    # Data Sanity check \n",
        "    assert train_size >= 0 and train_size <= 1.0, 'Train size out of bounds!'\n",
        "    assert test_size >= 0 and test_size <= 1.0, 'Test size out of bounds!'\n",
        "    assert train_size + test_size == 1.0, 'Train + Test should be equal to 1!'\n",
        "    \n",
        "    # Debug Flag \n",
        "    _LOCAL_DEBUG_ = False\n",
        "    \n",
        "    # Extract the x and y from the dataset\n",
        "    all_x = dataset[features]\n",
        "    all_y = dataset[target]\n",
        "    if _GLOBAL_DEBUG_ and _LOCAL_DEBUG_:\n",
        "        print(all_x.head())\n",
        "        print(all_y.head())\n",
        "        print('dataset.shape ', dataset.shape)\n",
        "\n",
        "    # Get the number of rows in df and no of elements in the pandas series \n",
        "    # NOTE - Both are multi-indexed\n",
        "    len_x = len(all_x.index.levels[0])\n",
        "    len_y = len(all_y.index.levels[0])\n",
        "    if _GLOBAL_DEBUG_ and _LOCAL_DEBUG_:\n",
        "        print('Len x ', len_x)\n",
        "        print('Len y ', len_y)\n",
        "    \n",
        "    # Some fancy calculations here for x\n",
        "    x_train = all_x.loc[all_x.index.levels[0]\\\n",
        "                        [:int(len_x*train_size)].astype(str).tolist()]\n",
        "    x_test = all_x.loc[all_x.index.levels[0]\\\n",
        "                       [int(len_x*train_size):int(len_x*train_size) + int(len_x*test_size)]\\\n",
        "                       .astype(str).tolist()]\n",
        "    if _GLOBAL_DEBUG_ and _LOCAL_DEBUG_:\n",
        "        print('x_train.shape ', x_train.shape)\n",
        "        print('x_test.shape ', x_test.shape)\n",
        "\n",
        "    # Some fancy calculations here for y as well\n",
        "    y_train = all_y.loc[all_y.index.levels[0]\\\n",
        "                        [:int(len_y*train_size)].astype(str).tolist()]\n",
        "    y_test = all_y.loc[all_y.index.levels[0]\\\n",
        "                       [int(len_y*train_size):int(len_y*train_size) + int(len_y*test_size)]\\\n",
        "                       .astype(str).tolist()]\n",
        "    if _GLOBAL_DEBUG_ and _LOCAL_DEBUG_:\n",
        "        print('y_train.shape ', y_train.shape)\n",
        "        print('y_test.shape ', y_test.shape)\n",
        " \n",
        "    return x_train, x_test, y_train, y_test "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rrKKH3lKfN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In our dataset all the columns except for the 'target' column are features\n",
        "# Temporarily drop the 'target' and extract the features  \n",
        "features = dataset.drop(['target'], axis=1).columns.values.tolist()\n",
        "\n",
        "# Get the train and test sets \n",
        "X_train, X_test, y_train, y_test = train_test_split(dataset=dataset,\\\n",
        "                                                    features=features,\\\n",
        "                                                    target='target',\\\n",
        "                                                    train_size=0.9,\\\n",
        "                                                    test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTR7sXjDOQIi",
        "colab_type": "code",
        "outputId": "dc566b7f-5614-4ee4-ce72-75281021d13c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# Validate the results \n",
        "print('dataset.shape ', dataset.shape)\n",
        "print('X_train.shape ', X_train.shape)\n",
        "print('X_test.shape ', X_test.shape)\n",
        "print('y_train.shape ', y_train.shape)\n",
        "print('y_test.shape ', y_test.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset.shape  (25535, 4)\n",
            "X_train.shape  (22855, 3)\n",
            "X_test.shape  (2680, 3)\n",
            "y_train.shape  (22855,)\n",
            "y_test.shape  (2680,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1MpA89NIlXG",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparameter Search\n",
        "We have the dataset in our hand with train and test splits.  \n",
        "Time to train our _Random Forest Classifier_, and look for the best set of  \n",
        "hyperparameters.  \n",
        "\n",
        "1. Create a plotting function to help in evaluating the performance of RFCs  \n",
        "2. Display the ranked feature importances \n",
        "3. Declare a hyperparameter _'grid'_ for the various RFCs to train on\n",
        "4. Train the RFCs \n",
        "5. Based on performance, choose the best set of hyperparameters. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNBC0I47LHG1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot(xs, ys, labels, title='', x_label='', y_label=''):\n",
        "    \"\"\"\n",
        "    Generate a plot of xs vs ys.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    xs : List\n",
        "        List of x-axis values  \n",
        "    ys : List\n",
        "        List of y-axis values  \n",
        "    labels : List\n",
        "        List of strings containing the name of legends\n",
        "    title : String\n",
        "        Plot Title\n",
        "    x_label : String\n",
        "        Name of the x-axis\n",
        "    y_label : String\n",
        "        Name of the y-axis\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None. Just plots the plot.\n",
        "    \"\"\"\n",
        "    plt.rcParams['figure.figsize'] = [12, 6]\n",
        "    for x, y, label in zip(xs, ys, labels):\n",
        "        plt.ylim((0.4, 0.7))\n",
        "        plt.plot(x, y, label=label)\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.xlabel(x_label)\n",
        "    plt.ylabel(y_label)\n",
        "\n",
        "    plt.legend(bbox_to_anchor=(1.04, 1), borderaxespad=0)\n",
        "    plt.show()\n",
        "\n",
        "    return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o905aKn-McnA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rank_features_by_importance(importances, feature_names):\n",
        "    \"\"\"\n",
        "    Ranks and Pretty prints the feature importances as \n",
        "    evaluated by the Random Forest Classifier. \n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    importances : ndarray\n",
        "        A numpy array containing feature importance values  \n",
        "    feature_names : List\n",
        "        A list of strings containing the names of features\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None. Just ranks and pretty prints the features along \n",
        "    with their importance. \n",
        "    \"\"\"\n",
        "    indices = np.argsort(importances)[::-1]\n",
        "    max_feature_name_length = max([len(feature) for feature in feature_names])\n",
        "\n",
        "    for x_train_i in range(len(importances)):\n",
        "        print('{number:>2}. {feature: <{padding}} ({importance})'.format(\n",
        "            number=x_train_i + 1,\n",
        "            padding=max_feature_name_length,\n",
        "            feature=feature_names[indices[x_train_i]],\n",
        "            importance=importances[indices[x_train_i]]))\n",
        "\n",
        "    return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLUsSjAmOfR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters \n",
        "# This is to get consistent results between each run.\n",
        "clf_random_state = 0\n",
        "\n",
        "n_days = 5\n",
        "n_stocks = len(ticker_list)\n",
        "\n",
        "clf_parameters = {\n",
        "    'criterion': 'entropy',\n",
        "    'min_samples_leaf': n_stocks * n_days,\n",
        "    'oob_score': True,\n",
        "    'n_jobs': -1,\n",
        "    'random_state': clf_random_state}\n",
        "n_trees_l = [5, 10, 25, 50, 75, 100]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V86wQtriJ0LB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2ba153f5-4996-4fa5-b9b9-52fe30c6c81a"
      },
      "source": [
        "%%timeit -n 1 -r 1\n",
        "# Train the Classifier \n",
        "train_score = []\n",
        "test_score = []\n",
        "feature_importances = []\n",
        "\n",
        "for n_trees in tqdm(n_trees_l, desc='Training Models', unit='Model'):\n",
        "    clf = RandomForestClassifier(n_trees, **clf_parameters)\n",
        "    clf.fit(X_train, y_train)\n",
        "    \n",
        "    train_score.append(clf.score(X_train, y_train.values))\n",
        "    test_score.append(clf.score(X_test, y_test.values))\n",
        "    feature_importances.append(clf.feature_importances_)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Models: 100%|██████████| 6/6 [00:12<00:00,  2.65s/Model]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 1: 12.7 s per loop\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBguIFTONDUu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "outputId": "c5ca26ec-0a9c-4eff-b1b4-02b30ddade70"
      },
      "source": [
        "# The most important features \n",
        "print('Features Ranked by Average Importance:\\n')\n",
        "rank_features_by_importance(np.average(feature_importances, axis=0), features)\n",
        "\n",
        "# Visualize the performance of the various classifiers \n",
        "plot([n_trees_l]*3,\n",
        "    [train_score, test_score],\n",
        "    ['train', 'test'],\n",
        "    'Random Forrest Accuracy',\n",
        "    'Number of Trees')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features Ranked by Average Importance:\n",
            "\n",
            " 1. close   (0.34364709008816563)\n",
            " 2. returns (0.33504430292733617)\n",
            " 3. volume  (0.3213086069844982)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuQAAAGDCAYAAABjvQUaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAEBCBHIAAAAgof8PlZ3N7XaiaRYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9PW6wHS6loz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}